[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, I am Alejandro, a Data Scientist and Machine Learning Engineer with experience in the finance sector.\nMy academic background includes a Bachelor of Science in Computer Science, a Big Data minor that I had the opportunity to study in the Netherlands and a Master’s degree in Artificial Intelligence.\nFor the last 5 years I have worked on projects related to finance, researching currency overlay solutions and developing advanced trading models. I have also worked utilizing quantum-inspired algorithms to solve well-known financial problems like Index Tracking and arbitrage strategies.\nIn this blog I share some thoughts and ideas that I think are interesting."
  },
  {
    "objectID": "posts/2021_07_29_dollar_index_checkpoint.html",
    "href": "posts/2021_07_29_dollar_index_checkpoint.html",
    "title": "Using Python to construct dollar indices",
    "section": "",
    "text": "In this post we review the methodology for constructing 2 dollar indices. We also code simple procedures to obtain those indices programmatically. Finally, we propose a method to compute a USD dollar index using PCA.\n# dependencies we are going to need\nimport investpy\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\nfrom functools import reduce\nfrom typing import Dict, Union\n#hide\nplt.style.use('https://gist.githubusercontent.com/Xylambda/4521dc6404594a715bbc7b75e8c1e2e1/raw/f4f466b27955169abd934428ed98c2be2e1201f2/bpyplot')"
  },
  {
    "objectID": "posts/2021_07_29_dollar_index_checkpoint.html#introduction",
    "href": "posts/2021_07_29_dollar_index_checkpoint.html#introduction",
    "title": "Using Python to construct dollar indices",
    "section": "Introduction",
    "text": "Introduction\nIn order to track the strength of the dollar, different organizations have developed different techniques to create their own dollar indexes. In this post we are going to see 2 methodologies to construct dollar indexes plus an extra one with PCA, though we will not discuss the results (at least in this post).\nThe most common way of constructing an index is by weighting the currency to track against a set of ponderated currencies. The currencies basket, the way weights are chosen and how we aggregate the different ponderated currencies define how we construct an index."
  },
  {
    "objectID": "posts/2021_07_29_dollar_index_checkpoint.html#dollar-indices",
    "href": "posts/2021_07_29_dollar_index_checkpoint.html#dollar-indices",
    "title": "Using Python to construct dollar indices",
    "section": "Dollar indices",
    "text": "Dollar indices\n\nUSDIDX\nThe dollar index is an index that measures the U.S. dollar value. It is built using a geometric mean of the following currencies with their respective weights: * Euro (EUR): 57.6 % weight * Japanese yen (JPY): 13.6 % weight. * Pound sterling (GBP): 11.9 % weight. * Canadian dollar (CAD): 11.9 % weight. * Swedish krona (SEK): 4.2 % weight. * Swiss franc (CHF): 3.6 % weight.\nIn the case of the main U.S. dollar index the weights remain static, which does not allow the index to capture well some market conditions. Furthermore, we see the Swedish Krona taking a relatively high weight, which is certainly outdated in the current market context.\n\n\nTrade weighted U.S. dollar index\nIn 1998, the staff of the Federal Reserve Board introduced a new set of indices, among which was the trade weighted dollar index.\nAlthough the dollar index is not well suited to capture rapid market movements (among other things), the trade weighted U.S. dollar index is not designed to fix this issue but to measure the strenght of the U.S. economy with respect to its trading partners.\nAccording to Loretan [1], the Federal Reserve Board’s nominal dollar index at time \\(t\\) can be defined as \\[\nI_{t} = I_{t-1} \\cdot \\prod_{j=1}^{N(t)} \\left( \\dfrac{e_{j,t}}{e_{j,t-1}} \\right)^{w_{j,t}}\n\\]\nLet’s break the formula to understand each one of the terms:\n\n\\(I_{t-1}\\) is the value of the index at time \\(t-1\\).\n\\(e_{j,t}\\) and \\(e_{j,t-1}\\) are the prices of the U.S. dollar in terms of foreign currency \\(j\\) at times \\(t\\) and \\(t-1\\).\n\\(w_{j,t}\\) is the weight of currency \\(j\\) at time \\(t\\).\n\\(N(t)\\) is the number of foreign currencies in the index at time \\(t\\).\n\\(\\sum_{j}w_{j,t} = 1\\).\n\nNotice how the index is computed using a geometric weighted average. As Loretan explains in [1], this is done because geometric averaging forces proportionately equal appreciation and depreciation of currencies to have the same numerical effect.\nThe weights \\(w_{j,t}\\) are computed as\n\\[\nw_{j,t} = \\frac{1}{2} \\mu_{US,j,t} + \\frac{1}{2} \\left( \\frac{1}{2} \\epsilon_{US, j,t} + \\frac{1}{2} \\tau_{US,jt} \\right)\n\\]\nwhich is nothing more than a linear combination of three submeasures of the degree of trade competition.\nIn the formula above, we can identify some terms that need further explanation:\n\n\\(\\mu_{US,j,t} = M_{US,j,t} / \\sum_{j=1}^{N(t)}M_{US, j,t}\\) is the economy’s bilateral import weight during period \\(t\\). Here, \\(M_{US,j,t}\\) represents the merchandise imports from economy \\(j\\) to the USA in year \\(t\\).\n\\(\\epsilon_{US, j,t} = X_{US,j,t} / \\sum_{j=1}^{N(t)}X_{US,j,t}\\) accounts for the US bilateral export share, where \\(X_{US,j,t}\\) represents the merchandise exports from the USA to economy \\(j\\) in year \\(t\\).\n\\(\\tau_{US,j,t} = \\sum_{k \\neq j, k \\neq US}^{N(t)} \\epsilon_{US, j,t} \\cdot \\mu_{k,j,t} / (1 - \\mu_{j,j,t})\\) measures a form of competition where US-produced goods may also compete with goods produced in economy \\(j\\) if the USA and economy \\(j\\) both export goods to buyers in third-market economies. Here, \\(\\mu_{k,j,t}\\) is the fraction of economy \\(k\\)’s merchandise imports from country \\(j\\) in year \\(t\\). The factor \\(1 / (1 - \\mu_{j,j,t})\\) is used to ensure weights sum up to 1.\n\nFortunately for us, we don’t have to manually compute the weights since they can be found at the Federal Reserve Board [4]."
  },
  {
    "objectID": "posts/2021_07_29_dollar_index_checkpoint.html#constructing-dollar-indices-in-python",
    "href": "posts/2021_07_29_dollar_index_checkpoint.html#constructing-dollar-indices-in-python",
    "title": "Using Python to construct dollar indices",
    "section": "Constructing dollar indices in Python",
    "text": "Constructing dollar indices in Python\n\nUS dollar index\nWe first start with the US dollar index. The construction is pretty simple since it is just a geometric weighted mean. The formula to compute the index is: \\[\nUSDIDX = 50.14348112 \\cdot EURUSD^{-0.576} \\cdot USDJPY^{0.136} \\cdot GBPUSD^{-0.119} \\cdot USDCAD^{0.091} \\cdot USDSEK^{0.042} \\cdot USDCHF^{0.036}\n\\]\nNotice how the sign of the exponent changes to account for the direction in which the currencies are expressed: if the USD is the base currency, the exponent is positive.\nThe number 50.14348112 is a correction factor to force the index to start at value 100.\n\n#hide\ncrosses = [\n    'AUD/USD', # Australia\n    'USD/ARS', # Argentina\n    'USD/BRL', # Brazil\n    'USD/CAD', # Canada\n    'USD/CNY', # China\n    'USD/CLP', # Chile\n    'USD/COP', # Colombia\n    'USD/HKD', # Hong Kong\n    'USD/IDR', # Indonesia\n    'USD/INR', # India\n    'USD/ILS', # Israel\n    'USD/JPY', # Japan\n    'USD/KRW', # Korea\n    'USD/MYR', # Malaysia\n    'USD/MXN', # Mexico\n    'USD/PHP', # Philippines\n    'USD/RUB', # Russia\n    'USD/SAR', # Saudi Arabia\n    'USD/SEK', # Sweeden\n    'USD/SGD', # Singapore\n    'USD/CHF', # Switzerland\n    'USD/TWD', # Taiwan\n    'USD/THB', # Thailand\n    'GBP/USD', # United Kingdom\n    'USD/VND', # vietnam\n    'EUR/USD' # Euro/Area\n]\n\n# download\ncrosses_dict = {}\nfor cross in crosses:\n    data = investpy.get_currency_cross_historical_data(\n        currency_cross=cross,\n        from_date='01/01/1950',\n        to_date='01/01/2022'\n    )\n    \n    crosses_dict[cross] = data[['Open', 'High', 'Low', 'Close']]#.loc['1988-03-04':]\n\n\n#collapse-show\ndef dollar_index(\n    currencies: Dict[str, pd.DataFrame], \n    weights: Dict[str, float]\n) -&gt; Union[pd.DataFrame, pd.Series]:\n    \"\"\"Compute the main U.S. dollar index.\n    \n    Weights must account for the currency cross direction.\n    \n    Parameters\n    ---------\n    currencies : dict\n        Dictionary containing the currency prices.\n    weights : dict\n        Dictionary containing the weights of each currency.\n        \n    Returns\n    -------\n    idx : pandas.DataFrame\n        U.S. dollar index.\n    \"\"\"\n    new = {}\n    \n    idx_crosses = ['EUR/USD', 'USD/JPY', 'GBP/USD', 'USD/CAD', 'USD/SEK', 'USD/CHF']\n    \n    # ponderate each currency\n    for key in idx_crosses:\n        new[key] = currencies[key] ** weights[key]\n        \n    # multiply all currencies\n    idx = reduce(\n        lambda a, b: a.multiply(b),\n        [new[key] for key in new.keys()]\n    )\n    \n    # add correction factor\n    idx *= 50.14348112\n    \n    return idx\n\n\n# create weights dictionary\nidx_crosses = ['EUR/USD', 'USD/JPY', 'GBP/USD', 'USD/CAD', 'USD/SEK', 'USD/CHF']\ndollar_idx_weights = dict(zip(idx_crosses, [-0.576, 0.136, -0.119, 0.091, 0.042, 0.036]))\n\n# compute the us dollar index\nusdidx = dollar_index(crosses_dict, dollar_idx_weights)\nusdidx['Close'].plot(figsize=(15,7), title='USD IDX')\n\nfindfont: Font family ['Franklin Gothic Book'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['Franklin Gothic Book'] not found. Falling back to DejaVu Sans.\n\n\n\n\n\n\n\n\n\n\n\nTrade weighted dollar index\nIn order to get the weights quickly and in a simple way, we can just copy the table from [4] and use Pandas to read our clipboard.\n\n#collapse-show\nweights = pd.read_clipboard()\nweights.set_index('Country or Region', inplace=True)\nweights.index = crosses + ['Total'] # put currency names instead of country names\n\n\nweights\n\n\n\n\n\n\n\n\n2021\n2020\n2019\n2018\n2017\n2016\n2015\n2014\n2013\n2012\n2011\n2010\n2009\n2008\n2007\n2006\n\n\n\n\nAUD/USD\n1.401\n1.401\n1.401\n1.416\n1.453\n1.443\n1.539\n1.557\n1.596\n1.749\n1.674\n1.549\n1.639\n1.480\n1.364\n1.309\n\n\nUSD/ARS\n0.442\n0.442\n0.442\n0.495\n0.550\n0.524\n0.510\n0.479\n0.530\n0.507\n0.513\n0.469\n0.447\n0.456\n0.380\n0.359\n\n\nUSD/BRL\n1.932\n1.932\n1.932\n1.952\n2.010\n1.903\n2.080\n2.338\n2.426\n2.428\n2.448\n2.194\n2.051\n2.114\n1.857\n1.779\n\n\nUSD/CAD\n13.337\n13.337\n13.337\n13.467\n13.685\n13.873\n14.062\n15.120\n15.513\n15.645\n15.883\n16.078\n15.844\n17.406\n18.089\n18.613\n\n\nUSD/CNY\n13.719\n13.719\n13.719\n15.767\n16.014\n15.635\n15.862\n15.645\n15.564\n15.099\n14.798\n14.848\n14.035\n13.009\n12.839\n12.326\n\n\nUSD/CLP\n0.640\n0.640\n0.640\n0.642\n0.633\n0.621\n0.651\n0.637\n0.706\n0.731\n0.701\n0.606\n0.611\n0.610\n0.586\n0.600\n\n\nUSD/COP\n0.615\n0.615\n0.615\n0.624\n0.598\n0.610\n0.653\n0.704\n0.661\n0.670\n0.659\n0.650\n0.678\n0.666\n0.591\n0.552\n\n\nUSD/HKD\n1.330\n1.330\n1.330\n1.438\n1.489\n1.433\n1.420\n1.450\n1.418\n1.314\n1.349\n1.317\n1.332\n1.233\n1.246\n1.239\n\n\nUSD/IDR\n0.665\n0.665\n0.665\n0.669\n0.678\n0.668\n0.698\n0.726\n0.762\n0.737\n0.770\n0.747\n0.699\n0.679\n0.616\n0.597\n\n\nUSD/INR\n2.869\n2.869\n2.869\n2.800\n2.674\n2.627\n2.458\n2.310\n2.264\n2.228\n2.220\n2.120\n2.069\n1.917\n1.746\n1.499\n\n\nUSD/ILS\n0.985\n0.985\n0.985\n1.037\n1.051\n1.122\n1.149\n1.138\n1.145\n1.154\n1.229\n1.183\n1.219\n1.257\n1.209\n1.168\n\n\nUSD/JPY\n6.377\n6.377\n6.377\n6.282\n6.383\n6.498\n6.359\n6.681\n7.072\n7.568\n7.191\n7.501\n7.263\n7.931\n8.340\n9.065\n\n\nUSD/KRW\n3.283\n3.283\n3.283\n3.273\n3.325\n3.319\n3.400\n3.347\n3.333\n3.264\n3.329\n3.278\n3.044\n2.937\n2.961\n3.076\n\n\nUSD/MYR\n1.278\n1.278\n1.278\n1.232\n1.261\n1.294\n1.229\n1.170\n1.127\n1.115\n1.198\n1.310\n1.310\n1.402\n1.472\n1.752\n\n\nUSD/MXN\n13.698\n13.698\n13.698\n13.452\n13.189\n13.341\n13.331\n12.867\n12.610\n12.261\n11.787\n11.604\n10.988\n10.686\n10.899\n11.281\n\n\nUSD/PHP\n0.662\n0.662\n0.662\n0.644\n0.642\n0.625\n0.601\n0.610\n0.608\n0.626\n0.613\n0.619\n0.615\n0.651\n0.672\n0.717\n\n\nUSD/RUB\n0.468\n0.468\n0.468\n0.514\n0.523\n0.462\n0.509\n0.699\n0.697\n0.692\n0.674\n0.591\n0.636\n0.761\n0.647\n0.635\n\n\nUSD/SAR\n0.511\n0.511\n0.511\n0.482\n0.562\n0.641\n0.694\n0.649\n0.732\n0.719\n0.592\n0.559\n0.664\n0.564\n0.529\n0.423\n\n\nUSD/SEK\n0.559\n0.559\n0.559\n0.549\n0.541\n0.543\n0.554\n0.576\n0.560\n0.607\n0.658\n0.709\n0.770\n0.774\n0.794\n0.829\n\n\nUSD/SGD\n1.891\n1.891\n1.891\n1.870\n1.681\n1.613\n1.569\n1.447\n1.517\n1.696\n1.719\n1.757\n1.692\n1.585\n1.685\n1.698\n\n\nUSD/CHF\n2.844\n2.844\n2.844\n2.632\n2.752\n2.599\n2.452\n2.400\n2.383\n2.295\n2.227\n2.362\n2.504\n2.166\n1.920\n1.823\n\n\nUSD/TWD\n2.145\n2.145\n2.145\n1.940\n1.941\n2.018\n2.010\n2.024\n2.008\n2.073\n2.285\n2.322\n2.055\n2.176\n2.358\n2.469\n\n\nUSD/THB\n1.088\n1.088\n1.088\n1.052\n1.065\n1.075\n1.053\n1.023\n1.030\n1.025\n1.014\n1.043\n1.019\n1.049\n1.063\n1.121\n\n\nGBP/USD\n5.416\n5.416\n5.416\n5.449\n5.291\n5.406\n5.526\n5.287\n5.107\n5.272\n5.338\n5.511\n6.082\n6.023\n6.150\n6.002\n\n\nUSD/VND\n1.761\n1.761\n1.761\n1.350\n1.322\n1.339\n1.148\n0.934\n0.806\n0.703\n0.642\n0.609\n0.593\n0.491\n0.413\n0.333\n\n\nEUR/USD\n20.086\n20.086\n20.086\n18.972\n18.685\n18.769\n18.481\n18.182\n17.824\n17.822\n18.493\n18.464\n20.141\n19.976\n19.575\n18.735\n\n\nTotal\n100.000\n100.000\n100.000\n100.000\n100.000\n100.000\n100.000\n100.000\n100.000\n100.000\n100.000\n100.000\n100.000\n100.000\n100.000\n100.000\n\n\n\n\n\n\n\n\n#collapse-show\ndef trade_weighted_usdidx(currencies: Dict[str, pd.DataFrame], weights: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Compute trade weighted dollar index.\n    \n    Parameters\n    ----------\n    currencies : dict\n        Dictionary containing all currency crosses.\n    weights : pandas.DataFrame\n        DataFrame containing the weights for each cross. The columns\n        should be years while the index should be the crosses.\n        \n    Returns\n    -------\n    idx : pd.DataFrame\n        Trade weighted dollar index.\n    \"\"\"\n    ponderated_crosses = {}\n    \n    for cross in currencies.keys():\n        \n        ponderations_per_year = []\n        \n        for year in weights.columns:\n            # invert prices if needed\n            if not cross.startswith('USD'):\n                prices = (1 / currencies[cross]).loc[str(year)]\n            else:\n                prices = currencies[cross].loc[str(year)]\n                \n            returns = prices / prices.shift(1)\n            weight = weights.loc[cross, year] / 100\n            \n            ponderations_per_year.append(returns ** weight)\n        \n        ponderated_crosses[cross] = pd.concat(ponderations_per_year)\n            \n    # multiply all currencies\n    idx = reduce(\n        lambda a, b: a.multiply(b),\n        [ponderated_crosses[key] for key in ponderated_crosses.keys()]\n    )\n    \n    idx.iloc[0, :] = 100\n    \n    return idx.cumprod()\n\nSince we could not retrieve the USD/SAR prices for the year 2021, we will only compute the index from 2006 to 2020.\n\nfed_idx = trade_weighted_usdidx(currencies=crosses_dict, weights=weights.drop('2021', axis=1))\nfed_idx.plot(figsize=(15,7), title='Trade weighted dollar index')\n\n\n\n\n\n\n\n\n\n\nBuild your own index\nNote: this idea was inspired by [2] and [6].\nIn this section, we will code a simple index using PCA to compute the weights of the currencies. The idea is to reduce the space into 1 component and then grab the loadings (projected eigenvalues) to use them as weights.\nThe ideal procedure will compute PCA using a rolling window, but I am gonna leave that as an exercise for the reader ;).\n\n#collapse\ncloses = []\nfor cr in crosses_dict.keys():\n    closes.append(crosses_dict[cr].loc[:, 'Close'])\n    \ncloses = pd.concat(closes, axis=1)\ncloses.columns = crosses_dict.keys()\n\nWe will apply PCA over the logarithmic daily returns.\n\nreturns = closes.apply(np.log).diff(1)\npca = PCA(n_components=1)\npca.fit(returns.dropna())\n\nPCA(n_components=1)\n\n\nNow, Scikit-Learn stores an eigenvector, for each principal component, for the projection space. We can use these values as our weights. Below there is a plot showing the values for these weights.\n\nweights_pca = pd.Series(index=returns.columns, data=pca.components_[0])\nweights_pca.plot.bar(figsize=(15,7), title='Weights')\n\n\n\n\n\n\n\n\nNotice how PCA is able to capture the sign of the returns: if the direction is XXX/USD, the weights are negative. Another thing to take into account is the fact that, generally, the crosses with the lowest weights are pegged currencies (USD/CNY, USD/HKD, USD/SAR, USD/VND).\nGoing back to the procedure, since the PCA weights do not sum up to 1, we have to normalize them but taking into account the sign:\n\nweights_pca = (weights_pca / weights_pca.abs().sum())\nweights_pca.plot.bar(figsize=(15,7), title='Fixed Weights')\n\n\n\n\n\n\n\n\n\n#collapse-show\ndef pca_dollar_index(\n    currencies: Dict[str, pd.DataFrame], \n    weights: Dict[str, float]\n) -&gt; Union[pd.DataFrame, pd.Series]:\n    \"\"\"Compute dollar index using PCA.\n    \n    Weights must account for the currency cross direction.\n    \n    Parameters\n    ---------\n    currencies : dict\n        Dictionary containing the currency prices.\n    weights : dict\n        Dictionary containing the weights of each currency.\n        \n    Returns\n    -------\n    idx : pandas.DataFrame\n        U.S. dollar index.\n    \"\"\"\n    new = {}\n    \n    # ponderate each currency\n    for key in idx_crosses:\n        new[key] = currencies[key] ** weights[key]\n        \n    # multiply all currencies\n    idx = reduce(\n        lambda a, b: a.multiply(b),\n        [new[key] for key in new.keys()]\n    )\n    \n    norm_factor = 100 / idx['Close'].dropna().iloc[0]\n    idx *= norm_factor\n    \n    return idx\n\nThe operation norm_factor = 100 / idx['Close'].dropna().iloc[0] is used to force the first day to be 100, as in the other indices.\n\npca_index = pca_dollar_index(crosses_dict, weights_pca)\npca_index.plot(figsize=(15,7), title='PCA Index')\n\n\n\n\n\n\n\n\nPutting all together we can see how the indices evolve:\n\n#collapse\nall_indices = pd.concat(\n    [usdidx['Close'], fed_idx['Close'], pca_index['Close']],\n    axis=1\n)\nall_indices.columns = ['USD IDX', 'FED IDX', 'PCA IDx']\nall_indices.plot(figsize=(15,7))\n\n\n\n\n\n\n\n\nAnd their correlations\n\n#collapse-hide\nplt.figure(figsize=(14,8))\nsns.heatmap(all_indices.corr(), annot=True, annot_kws={'fontsize':20})\n\nfindfont: Font family ['Franklin Gothic Book'] not found. Falling back to DejaVu Sans.\n\n\n\n\n\n\n\n\n\nAs expected, all indices are highly correlated, which means they have a strong linear codependence."
  },
  {
    "objectID": "posts/2021_07_29_dollar_index_checkpoint.html#conclusions",
    "href": "posts/2021_07_29_dollar_index_checkpoint.html#conclusions",
    "title": "Using Python to construct dollar indices",
    "section": "Conclusions",
    "text": "Conclusions\nIn this post we’ve reviewed 3 ways of computing a dollar index: * USDIDX: the most common dollar index.\n\nTrade weighted dollar index: an index designed by the USA Federal Reserve to measure how well is USA performing in relation to its trading parters.\nPCA index: based on [2] and [6], which is an index whose weights have been computed depending on the eigenvalues of the covariance matrix of the closing prices returns.\n\nThe construction of the indices is not perfect in the sense that they don’t replicate the true values of the indices. This is due to the lack of data on some days plus a difference in the prices caused by the subset of the market that was used to get the prices not being the same (probably).\nAn additional analysis will have to be carried out to check which is index is better, but that is out of the scope of this post. You can check [7] to have an idea of how to evaluate the goodness of an index, though it will depend on the use case."
  },
  {
    "objectID": "posts/2021_07_29_dollar_index_checkpoint.html#references",
    "href": "posts/2021_07_29_dollar_index_checkpoint.html#references",
    "title": "Using Python to construct dollar indices",
    "section": "References",
    "text": "References\n\n[1] Mico Loretan - Indexes of the Foreign Exchange Value of the Dollar\n[2] Musa Essayyad, Khaled Albinali and Omar Al-Titi - Constructing an alternative dollar index to gauge the movements in currency markets\n[3] The Ice - U.S. Dollar Index Contracts\n[4] Federal Reserve Board - Total Trade Weights\n[5] S&P Dow Jones Indices: Index Methodology\n[6] Yao Lei Xu - Stock Market Analytics with PCA.\n[7] Cerno Capital - Is the US Dollar Index Fit for Purpose"
  },
  {
    "objectID": "posts/28_07_2024_index_tracking.html",
    "href": "posts/28_07_2024_index_tracking.html",
    "title": "Index Tracking: a naive approach",
    "section": "",
    "text": "We review in this post a naive approach to solve the Index Tracking problem using Principal Component Analysis."
  },
  {
    "objectID": "posts/28_07_2024_index_tracking.html#introduction",
    "href": "posts/28_07_2024_index_tracking.html#introduction",
    "title": "Index Tracking: a naive approach",
    "section": "1. Introduction",
    "text": "1. Introduction\nA financial index is a number that represents the aggregate value of a group of items. In particular, a financial index is composed of a collection of assets, such as stocks or bonds (each instrument associated with a weight that determines its importance on the overall basket), which captures the value of a specific market or a segment of it (Benidis, K., Feng, Y., & Palomar, D. P. (2018)).\nIndex tracking is a well-known problem in passive investment that consists in designing a portfolio, called tracking portfolio, that closely follows a benchmark index. Usually, the tracking portfolio is constructed using a subset of the original financial instruments that compose the index.\n\n1.1. Tracking Error\nTo measure the goodness of a tracking portfolio with respect to the index we use the tracking error (TE). The TE is usually defined as the standard deviation of the difference between the returns of the tracking portfolio and the returns of the index\n\\[\nTE = Std(r_{index} - r_{tracking}),\n\\]\nwhere \\(r_{index}\\) are the returns of the index and \\(r_{tracking}\\) are the returns of the tracking portfolio, defined as\n\\[\nr_{tracking}=\\sum_{i}^{k} w_{i} \\cdot r_{i}.\n\\]\nHere, \\(w_{i}\\) and \\(r_{i}\\) are the weights and returns of asset \\(i\\) and \\(k\\) is the number of assets in the tracking portfolio."
  },
  {
    "objectID": "posts/28_07_2024_index_tracking.html#methodology",
    "href": "posts/28_07_2024_index_tracking.html#methodology",
    "title": "Index Tracking: a naive approach",
    "section": "2. Methodology",
    "text": "2. Methodology\n\n2.1. Principal component Analysis\nPrincipal Component Analysis (PCA) is a statistical technique that allows expressing a set of variables as a set of linearly uncorrelated variables called principal components. We are not going to dive into the definition and computations needed to perform PCA. Instead, we are going to focus on using this technique to select a subset of relevant instruments, from the total amount of instruments that compose and index, to construct a tracking portfolio.\n\n\n2.2. Dataset\nWe work in this post with the adjusted close prices of SP500 constituents, downloaded from Yahoo finance on date 2024-05-30. Survivorship bias has not been taken into account and that is why some tickers may be missing. In any case, this is not important for the objective of the post.\nWhenever we work with the dataset, we discard the tickers that have any missing values in the lookback period."
  },
  {
    "objectID": "posts/28_07_2024_index_tracking.html#results",
    "href": "posts/28_07_2024_index_tracking.html#results",
    "title": "Index Tracking: a naive approach",
    "section": "3. Results",
    "text": "3. Results\nWe apply in this section the PCA-based index tracking methodology to the SP500. The idea is to generate a portfolio of size \\(k\\) every month. In actual fact, we are not truly rebalancing because we are not going to take into account the previous portfolio. We are also not going to take into account weight drift (or style drift) since we are not considering neither working with shares nor with a budget.\nThe following cells load the SP500 component prices and the index itself. Then, we compute the relative returns.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nfrom sklearn.decomposition import PCA\n\n\ndataset = pd.read_csv(\"data/sp500.csv\", index_col=0)\ndataset.index = pd.DatetimeIndex(dataset.index)\n\n# the index is the last column\ncomponents = dataset.iloc[:, :-1]\nindex = dataset.iloc[:, -1:]\n\nasset_returns = components.pct_change()\nindex_returns = index.pct_change().squeeze()\n\n\ndef get_portfolio_weights(\n    asset_returns,\n    computation_date,\n    portfolio_size,\n    lookback=pd.offsets.BusinessDay(252 * 2)\n):\n    \"\"\"Compute portfolio weights using PCA for a given portfolio size.\n\n    Returns are standardized using \"lookback\" periods, and the portfolio is\n    constructed by selecting the weights on the assets that contribute the most\n    to the variance.\n\n    Parameters\n    ----------\n    asset_returns : pandas.DataFrame\n        Pandas DataFrame containing the returns of the instruments that compose\n        the index.\n    computation_date : pandas.Timestamp\n        Date at which to perform the portfolio construction.\n    portfolio_size : int\n        Number of non-zero weights in the portfolio.\n    lookback : pandas.DateOffset\n        Number of days to consider to build the portfolio.\n\n    Returns\n    -------\n    weights : pandas.Series\n        A pandas Series of computed weights for the given computation date.\n    \"\"\"\n    ini = computation_date - lookback\n    end = computation_date\n\n    # subset returns to train interval and drop any asset with missing values\n    in_sample_asset_returns = asset_returns.loc[ini:end]\n    in_sample_asset_returns = in_sample_asset_returns.dropna(axis=1)\n\n    mean = in_sample_asset_returns.mean()\n    std = in_sample_asset_returns.std()\n\n    in_sample_asset_returns = (in_sample_asset_returns - mean) / std\n\n    model = PCA()\n    components = model.fit_transform(in_sample_asset_returns)\n    contributions = np.sum(np.abs(components), axis=0)\n    \n    # Select the top `cardinality` stocks based on their contributions\n    selected_indices = np.argsort(contributions)[-portfolio_size:]\n    \n    # Normalize the weights for the selected stocks\n    selected_contributions = contributions[selected_indices]\n    selected_weights = selected_contributions / np.sum(selected_contributions)\n    \n    # Create a full weight vector with zero weights for unselected stocks\n    full_weights = np.zeros(in_sample_asset_returns.shape[1])\n    full_weights[selected_indices] = selected_weights\n\n    weights = pd.Series(\n        full_weights,\n        index=in_sample_asset_returns.columns\n    )\n    weights = weights.reindex(asset_returns.columns).fillna(0)\n    weights.name = computation_date\n    weights = weights.to_frame()\n    \n    return weights\n\n\ndef get_portfolio_weights_at_different_dates(\n    asset_returns,\n    portfolio_size,\n    rebalance_dates=None,\n    lookback=pd.offsets.BusinessDay(252 * 2)\n):\n    \"\"\"Compute portfolio weights using PCA for different dates.\n\n    Returns are standardized using \"lookback\" periods, and the portfolio is\n    constructed by selecting the weights on the assets that contribute the most\n    to the variance.\n\n    Parameters\n    ----------\n    asset_returns : pandas.DataFrame\n        Pandas DataFrame containing the returns of the instruments that compose\n        the index.\n    portfolio_size : int\n        Number of non-zero weights in the portfolio.\n    rebalance_dates : list of pandas.Timestamp, optional, default: None\n        Dates at which to compute a new set of portfolio weights.\n    lookback : pandas.DateOffset\n        Number of days to consider to build the portfolio.\n\n    Returns\n    -------\n    weights_df : pandas.Series\n        A pandas DataFrame of computed weights for different computation dates.\n    \"\"\"\n    if rebalance_dates is None:\n        months = range(1, 13)\n        years = range(2010, 2025)\n        rebalance_dates = []\n        for m in months:\n            for y in years:\n                t = pd.Timestamp(year=y, month=m, day=1)\n                rebalance_dates.append(t)\n\n    # construct a portfolio for each date\n    weight_dict = {}\n    for computation_date in rebalance_dates:\n        _weight = get_portfolio_weights(\n            asset_returns=asset_returns,\n            computation_date=computation_date,\n            portfolio_size=portfolio_size,\n            lookback=lookback,\n        )\n        weight_dict[computation_date] = _weight.squeeze()\n\n    # reindex weights to have the same index as asset_returns\n    weights_df = pd.DataFrame(weight_dict).T\n    weights_df = weights_df.sort_index()\n    weights_df = weights_df.reindex(asset_returns.index, method=\"ffill\")\n\n    return weights_df\n\nWe compute a portfolio the first day of each month and year from 2010 to 2024\n\nmonths = range(1, 13)\nyears = range(2010, 2025)\n\nrebalance_dates = []\nfor m in months:\n    for y in years:\n        t = pd.Timestamp(year=y, month=m, day=1)\n        rebalance_dates.append(t)\n\nWe consider different portfolio sizes for the experiment. Theoretically, the bigger the portfolio the smaller the tracking error.\n\nportfolio_sizes = [5, 15, 30, 60, 100, 300]\n\nWe always work with the last two years of data, considering the last available date the portfolio computation date.\n\nweights_dict = {}\n\nfor k in portfolio_sizes:\n    weights_df = get_portfolio_weights_at_different_dates(\n        asset_returns=asset_returns,\n        portfolio_size=k,\n        rebalance_dates=rebalance_dates,\n        lookback=pd.offsets.BusinessDay(252 * 2)\n    )\n    weights_dict[k] = weights_df\n\nBelow we plot the rolling tracking error to evaluate this metric using a sliding-window approach. This allows us to asses the evolution of the tracking portfolio quality over time.\n\ndef get_tracking_error(asset_returns, index_returns, portfolio_weights_matrix):\n    tracking_portfolio = (asset_returns * portfolio_weights_matrix).sum(axis=1)\n    _index = index_returns.loc[tracking_portfolio.index].squeeze()\n\n    spread = tracking_portfolio - _index.loc[tracking_portfolio.index]\n    rolling_tracking_error = spread.rolling(252).std()\n    rolling_tracking_error *= np.sqrt(252) * 100\n    return rolling_tracking_error\n\n\nfig, ax = plt.subplots(1, 1, figsize=(17, 8))\n\nfor k, weights in weights_dict.items():\n    rolling_tracking_error = get_tracking_error(\n        asset_returns=asset_returns.loc[\"2010\":\"2024\"],\n        index_returns=index_returns.loc[\"2010\":\"2024\"],\n        portfolio_weights_matrix=weights.loc[\"2010\":\"2024\"]\n    )\n    rolling_tracking_error.plot(\n        ls=\"--\", marker=\".\", mfc=\"w\", lw=1, ax=ax, label=f\"Portfolio size: {k}\"\n    )\n\nax.grid(True, alpha=.3)\nax.legend(fontsize=16, ncol=2)\nax.set_title(\"Yearly rolling tracking error\", fontsize=23);\nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_ylabel(\"Yearly rolling TE\", fontsize=20)\nax.set_xlabel(\"Date\", fontsize=20)\nax.tick_params(axis='both', which='major', length=0, labelsize=20)\n\n\n\n\n\n\n\n\nAs expected, we clearly see the tracking error decreases with the size of the portfolio: the greater the number of elements the smaller the TE is. We notice significantly higher tracking errors at 2014, 2020 and 2023. The ones at 2020 and 2023 are caused by an increase in the volatility of the index, as shows below. The 2014 is probably due to the quality of the tracking not being very good, either because the PCA does not capture the dynamics or because of the covariance matrix used (in sample over the returns of the last 2 years) is significantly different from the matrix on the test period.\n\nfig, ax = plt.subplots(1, 1, figsize=(17, 8))\n\n(100 * np.sqrt(252) * index_returns.rolling(252).std()).loc[\"2010\":\"2024\"].plot(ax=ax)\n\nax.grid(True, alpha=.3)\nax.legend(fontsize=16, ncol=2)\nax.set_title(\"Yearly SP500 volatility\", fontsize=23);\nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_ylabel(\"Yearly volatility\", fontsize=20)\nax.set_xlabel(\"Date\", fontsize=20)\nax.tick_params(axis='both', which='major', length=0, labelsize=20)"
  },
  {
    "objectID": "posts/28_07_2024_index_tracking.html#why-is-it-naive",
    "href": "posts/28_07_2024_index_tracking.html#why-is-it-naive",
    "title": "Index Tracking: a naive approach",
    "section": "4. Why is it “Naive”?",
    "text": "4. Why is it “Naive”?\nThe approach we have used is far from desirable. Some reasons why:\n\nPCA does not directly address the minimization of the tracking error.\nPCA focuses on explaining the variance of the data, which may not be the best way to capture market movements.\nConstraints: we have somewhat included the cardinality constraing on our portfolio construction but it was a far from elegant solution. What if we want to add more constraints? For intance: what if we want a portfolio computed at time \\(t+1\\) to be derived from the portfolio at time \\(t\\), limiting for example the number of assets that are allowed to change from \\(t\\) to \\(t+1\\)? PCA is not suited for these constraints."
  },
  {
    "objectID": "posts/28_07_2024_index_tracking.html#conclusions",
    "href": "posts/28_07_2024_index_tracking.html#conclusions",
    "title": "Index Tracking: a naive approach",
    "section": "5. Conclusions",
    "text": "5. Conclusions\nIn this post we have briefly review the definition of Index Tracking and we have applied Principal Component Analysis to construct tracking portfolios. We have tested the methodology using the SP500 dataset, for which we have computed portfolios from different sizes.\nResults show that we can achieve a 5% tracking error using portfolio sizes of 60 or more.\nFinally, we have stated that PCA is probably the most naive way to approach the Index Tracking problem, since it has many caviats."
  },
  {
    "objectID": "posts/28_07_2024_index_tracking.html#references",
    "href": "posts/28_07_2024_index_tracking.html#references",
    "title": "Index Tracking: a naive approach",
    "section": "References",
    "text": "References\n\nBenidis, K., Feng, Y., & Palomar, D. P. (2018). Optimization methods for financial index tracking: From theory to practice. Foundations and Trends® in Optimization, 3(3), 171-279."
  },
  {
    "objectID": "posts/20_08_2024_ml_notes_4.html",
    "href": "posts/20_08_2024_ml_notes_4.html",
    "title": "Machine Learning Notes IV: Logistic Regression",
    "section": "",
    "text": "Personal notes for myself about logistic regression and how to implement it from scratch using gradient descent.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.base import ClassifierMixin\nfrom scipy.special import expit"
  },
  {
    "objectID": "posts/20_08_2024_ml_notes_4.html#introduction",
    "href": "posts/20_08_2024_ml_notes_4.html#introduction",
    "title": "Machine Learning Notes IV: Logistic Regression",
    "section": "1. Introduction",
    "text": "1. Introduction\nDespite its name, logistic regression is a classification algorithm. The regression term from the name comes from the fact that the algorithm is just a linear regression passed through a logits function, commonly known as sigmoid function. Let’s put this into mathematical terms.\n\\[\n\\hat{Y} = \\sigma(Z) = \\sigma \\left( \\dfrac{1}{1 + e^{-X B}} \\right).\n\\]\nHere, \\(X\\) is a matrix of shape \\((n, p+1)\\), where \\(p\\) are the number of features and \\(n\\) the number of samples. The extra 1 accounts for the intercept. Consequently, \\(B\\) is a column-vector of shape \\((p+1, 1)\\) of parameters to optimize. The term \\(Z=XB\\) is the linear regression. Refer to this post for more in deepth information.\nThe loss function we use for this algorithm is the binary cross-entropy, defined in matrix form as\n\\[\nL(\\hat{Y}) = - \\dfrac{1}{n} \\left[ Y \\cdot log(\\hat{Y}) +  (1 - Y) \\cdot log(1- \\hat{Y}) \\right]\n\\]\n\n1.1. Gradient descent solution\nUnfortunately, there is no closed-form solution for estimating the \\(B\\) parameters in the case of logistic regression, but we can approach the problem using iterative methods such as gradient descent.\nNote that the loss function \\(L\\) is a composition of functions such that \\(L(\\hat{Y} (Z (B)))\\). To compute the gradient of the loss function we can simply apply the chain rule\n\\[\n\\dfrac{\\partial L}{\\partial B} = \\dfrac{\\partial L}{\\partial \\hat{Y}} \\cdot \\dfrac{\\partial \\hat{Y}}{\\partial Z} \\cdot \\dfrac{\\partial Z}{\\partial B},\n\\]\nand then derive each term on its own. Let us start by the first term \\(\\dfrac{\\partial L}{\\partial \\hat{Y}}\\). We have to apply the product rule of derivatives to each one of the terms in the loss function\n\\[\n\\dfrac{\\partial L}{\\partial \\hat{Y}} = - \\left[ \\dfrac{Y}{\\hat{Y}} + (1 - Y) \\cdot \\dfrac{1}{1 - \\hat{Y}} \\cdot (-1) \\right].\n\\]\nThen, we just expand the terms and reduce\n\\[\n\\dfrac{\\partial L}{\\partial \\hat{Y}} = \\dfrac{\\hat{Y} - Y}{\\hat{Y} (1 - \\hat{Y})}.\n\\]\nThe next term is the derivative of \\(\\hat{Y}\\) with respect to \\(Z\\). Remember \\(\\hat{Y}\\) is the results of applying the sigmoid function element-wise to \\(Z\\), and so this derivative is the derivative of the sigmoid function:\n\\[\n\\dfrac{\\partial \\hat{Y}}{\\partial Z} = \\sigma(Z) \\cdot (1 - \\sigma(Z)) = \\hat{Y} (1 - \\hat{Y}).\n\\]\nLastly, the derivative of \\(Z\\) with respect to the coefficients vector \\(B\\) is trivial\n\\[\n\\dfrac{\\partial Z}{\\partial B} = X.\n\\]\nPutting everything together we have\n\\[\n\\dfrac{\\partial L}{\\partial B} = X^{T} \\left[ \\dfrac{\\hat{Y} - Y}{\\hat{Y} (1 - \\hat{Y})} \\cdot \\hat{Y} (1 - \\hat{Y}) \\right] = X^{T} (\\hat{Y} - Y).\n\\]\nNotice how the \\(X\\) matrix has been transposed to make sense of the product operation. The final gradient of the binary cross-entropy loss then becomes\n\\[\n\\nabla L(B) = \\dfrac{1}{n} \\cdot X^{T} (\\hat{Y} - Y).\n\\]\n\n\n1.1. Multiclass classification\nWe won’t dive into the multiclass problem, but note that we only need to change the sigmoid function for the softmax function and use the general version of the binary cross-entropy problem, called cross-entropy problem."
  },
  {
    "objectID": "posts/20_08_2024_ml_notes_4.html#coding-logistic-regression-from-scratch",
    "href": "posts/20_08_2024_ml_notes_4.html#coding-logistic-regression-from-scratch",
    "title": "Machine Learning Notes IV: Logistic Regression",
    "section": "2. Coding logistic regression from scratch",
    "text": "2. Coding logistic regression from scratch\n\nclass LogisticRegression(ClassifierMixin):\n    \"\"\"Gradient descent logistic regression.\n\n    Estimates the parameters using a gradient descent optimization\n    approach.\n    \n    Parameters\n    ----------\n    l_rate : float, optional, default: 1e-3\n        Learning rate.\n    batch_size : int, optional, default: 1\n        Batch size for the gradient descent algorithm. 1 will perform\n        a stochastic gradient descent.\n    fit_intercept : bool, optional, default: True\n        Whether to add the intercept or not to the regression.\n    n_epochs : int, optional, default: 1000\n        Number of epochs for the training.\n    epsilon : float, optional, default: 1e-8\n        Epsilon for the loss function to avoid divisions by zero.\n    reduce : str, optional, default: \"sum\", {\"sum\", \"mean\"}\n        Function to reduce the loss.\n    \"\"\"\n    def __init__(\n        self,\n        l_rate=1e-3,\n        batch_size=1,\n        fit_intercept=True,\n        n_epochs=1_000,\n        epsilon=1e-8,\n        reduce=\"sum\",\n    ):\n        self.l_rate = l_rate\n        self.batch_size = batch_size\n        self.fit_intercept = fit_intercept\n        self.n_epochs = n_epochs\n        self.epsilon = epsilon\n        self.reduce = reduce\n\n        # attributes\n        self.coefficients_ = None\n        self.loss = []\n\n    def _binary_cross_entropy_loss(self, y_true, y_est, batch_size):\n        epsilon = self.epsilon\n        y_class_0 = y_true * np.log(y_true + epsilon)\n        y_class_1 = (1 - y_true) * np.log(1 - y_est + epsilon)\n\n        if self.reduce == \"mean\":\n            return -(1 / batch_size) * (y_class_0 + y_class_1).mean()\n        elif self.reduce == \"sum\":\n            return -(1 / batch_size) * (y_class_0 + y_class_1).sum()\n        else:\n            raise ValueError(f\"Unsupported value for 'reduce': {self.reduce}\")\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        n_epochs = self.n_epochs\n        fit_intercept = self.fit_intercept\n        l_rate = self.l_rate\n        batch_size = self.batch_size\n        \n        if fit_intercept:\n            X = np.hstack((np.ones((n_samples, 1)), X))\n\n        coefficients_ = np.zeros(X.shape[1])\n\n        for _ in range(n_epochs):\n            for i in range(0, n_samples, batch_size):\n                X_batch = X[i:i + batch_size]\n                y_batch = y[i:i + batch_size]\n\n                # make prediction\n                prediction = expit(X_batch @ coefficients_)\n\n                # compute loss\n                _loss = self._binary_cross_entropy_loss(\n                    y_batch, prediction, batch_size=batch_size\n                )\n                self.loss.append(_loss)\n\n                # compute gradient\n                gradient = (1 / batch_size) * X_batch.T @ (prediction - y_batch)\n\n                # update parameters\n                coefficients_ -= l_rate * gradient\n\n        self.coefficients_ = coefficients_\n\n    def predict(self, X, threshold=0.5):\n        if self.fit_intercept:\n            X = np.hstack((np.ones((X.shape[0], 1)), X))\n\n        probs = expit(X @ self.coefficients_)\n        y_pred = np.where(probs &lt; threshold, 0, 1)\n        return y_pred\n\n    def predict_proba(self, X):\n        if self.fit_intercept:\n            X = np.hstack((np.ones((X.shape[0], 1)), X))\n\n        return expit(X @ self.coefficients_)\n\nAs with the previous posts, we generate a synthetic dataset using Scikit-Learn.\n\nX, y = make_classification(n_samples=500, n_features=2, n_informative=2, n_redundant=0, n_classes=2, random_state=10)\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\nax.scatter(X[:, 0], X[:, 1], c=y)\nax.grid(True, alpha=.3)\nax.set_title(\"Dataset\", fontsize=24)\nax.set_xlabel(\"Feature $x_{1}$\", fontsize=20)\nax.set_ylabel(\"Feature $x_{2}$\", fontsize=20)\nax.tick_params(labelsize=20)\n\n\n\n\n\n\n\n\n\nkf = KFold(n_splits=5)\nclassification_threshold = 0.5\n\nroc_scores = []\nfor train_idx, test_idx in kf.split(X):\n    model = LogisticRegression(n_epochs=5_000, batch_size=32)\n\n    X_train = X[train_idx]\n    y_train = y[train_idx]\n\n    X_test = X[test_idx]\n    y_test = y[test_idx]\n\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    score = roc_auc_score(y_true=y_test, y_score=y_pred)\n    roc_scores.append(score)\n\nResults show a roc auc score of 0.93 on average for 5 K-fold split. Pretty good results for this dataset.\n\nnp.array(roc_scores).mean()\n\n0.9314960711631561"
  },
  {
    "objectID": "posts/20_08_2024_ml_notes_4.html#strengths-and-weaknesses",
    "href": "posts/20_08_2024_ml_notes_4.html#strengths-and-weaknesses",
    "title": "Machine Learning Notes IV: Logistic Regression",
    "section": "3. Strengths and Weaknesses",
    "text": "3. Strengths and Weaknesses\nA summary of strenghts and weaknesses of this model.\n\nPros\n\nInterpretable.\nPprovides probability estimates.\nEffective for binary and multiclass classification.\nEfficient.\n\n\n\nCons\n\nAssumes linearity in log-odds.\nNot suitable for non-linear boundaries, since it works drawing lines.\nSensitive to multicollinearity.\nNumber of observations must be greater than the number of features to avoid overfitting."
  },
  {
    "objectID": "posts/2021_08_15_online_beta_with_kalman_filter_checkpoint.html",
    "href": "posts/2021_08_15_online_beta_with_kalman_filter_checkpoint.html",
    "title": "Online beta estimation with the Kalman Filter",
    "section": "",
    "text": "In this post we briefly review the Kalman Filter and we use it to compute the beta between 2 stock returns using Python, though the procedure can also be used in many other fields with an appropiate translation.\n#hide\nimport warnings\nwarnings.filterwarnings('ignore')\n# dependencies we are going to need\nimport investpy\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom kalmanfilter import KalmanFilter\nfrom sklearn.linear_model import LinearRegression\n#hide\nplt.rcParams[\"font.family\"] = \"Times New Roman\""
  },
  {
    "objectID": "posts/2021_08_15_online_beta_with_kalman_filter_checkpoint.html#introduction",
    "href": "posts/2021_08_15_online_beta_with_kalman_filter_checkpoint.html#introduction",
    "title": "Online beta estimation with the Kalman Filter",
    "section": "1. Introduction",
    "text": "1. Introduction\nThe Kalman Filter is an optimal estimation algorithm capable of finding the true state of a signal given that this signal is noisy and/or incomplete. There are many applications where the Kalman filter is an appropiate tool; in this post we see how we can mix the Kalman filter with a linear regression to dynamically compute the beta between 2 stocks.\n\n1.1. Kalman filter review\nThe Kalman assumes a dynamic linear system given by two equations \\[\n\\begin{matrix}\nx_{k} = A_{k} x_{k} + B u_{k} + q_{k} \\\\\nz_{k} = H_{k} x_{k} + r_{k}\n\\end{matrix}\n\\]\nThe first equation determines the expression that gives the true state of the system. The second equation tells us that any observation \\(z\\) at time \\(k\\) can be expressed as a linear combination of the state \\(x_{k}\\) using the observation model \\(H_{k}\\) plus some noise \\(r_{k}\\).\nThe Kalman Filter estimates the true estate using a feedback control-loop of 2 stages: predict and update.\n\nPredict step \\[\n\\begin{matrix}\n\\hat{x}_{k}^{-} = A_{k} \\hat{x}_{k-1}^{-} + B_{k} u_{k-1} \\\\\nP_{k}^{-} = A_{k}P_{k-1}A_{k}^{T} + Q_{k}\n\\end{matrix}\n\\]\nUpdate step \\[\n\\begin{matrix}\nK_k = P_{k}^{-} H_{k}^{T} (H_{k} P_{k}^{-} H_{k}^{T} + R_{k})^{-1} \\\\\n\\hat{x}_{k} = \\hat{x}_{k}^{-} + K_k (z_k - H_{k} \\hat{x}_{k}^{-}) \\\\\nP_k = (I - K_k H) P_{k}^{-}\n\\end{matrix}\n\\]\n\nWe won’t cover the mathematical derivation of the filter since it is very complex and it would only add useless noise to the post, but you can read it at [3] and [4].\n\n\n1.2. Linear regression & Kalman filtering\nRecall the typical linear regression equation \\[\n\\hat{Y} = \\hat{\\beta}_{0} + \\sum_{j=0}^{p} X_{j} \\hat{\\beta}_{j}\n\\]\nwhich is equivalent to \\[\n\\hat{Y} = X^{T} \\hat{\\beta}\n\\]\nif we include the constant variable 1 in \\(X\\), include \\(\\hat{\\beta}_{0}\\) in the vector of coefficients \\(\\hat{\\beta}\\) and then write the linear model in vector form as an inner product, where \\(X^{T}\\) denotes vector or matrix transpose (\\(X\\) is a column vector) [5].\nFor two dimensions, we can express the above formula as \\[\n\\hat{Y} = (1, x_{j})\\begin{pmatrix} \\hat{\\beta}_{0} \\\\ \\hat{\\beta}_{1} \\end{pmatrix}\n\\]\nThe equation above is similar to the observation equation of the Kalman Filter \\(z_{k} = H_{k} x_{k} + r_{k}\\) and so we can write the following expression \\[\nz_{k} = (1, H_{k})\\begin{pmatrix} x_{k,0} \\\\ x_{k,1} \\end{pmatrix} + r_{k}\n\\]\nThis is telling us that we can plug one stock in the \\(z_{k}\\) and the other in the \\(H_{k}\\) to compute a dynamic beta between both stocks. \\(x_{k,0}\\) would be our alpha and \\(x_{k,1}\\) our beta."
  },
  {
    "objectID": "posts/2021_08_15_online_beta_with_kalman_filter_checkpoint.html#numerical-experiments",
    "href": "posts/2021_08_15_online_beta_with_kalman_filter_checkpoint.html#numerical-experiments",
    "title": "Online beta estimation with the Kalman Filter",
    "section": "2. Numerical experiments",
    "text": "2. Numerical experiments\nWe first download the stock prices of Amazon and Microsoft and compute their arithmetic relative returns. We use arithmetic returns because of the difference in scale of absolute returns.\n\n#collapse-hide\namazon = investpy.get_stock_historical_data(\n    stock='AMZN',\n    country='United States',\n    from_date='01/01/1910',\n    to_date='28/08/2021'\n)\n\n\nmicrosoft = investpy.get_stock_historical_data(\n    stock='MSFT',\n    country='United States',\n    from_date='01/01/1910',\n    to_date='28/08/2021'\n)\n\nama_returns = amazon['Close'].pct_change()\nmic_returns = microsoft['Close'].pct_change()\n\nprices = pd.concat([amazon['Close'], microsoft['Close']], axis=1).dropna()\nprices.columns = ['Amazon', 'Microsoft']\n\nreturns = pd.concat([ama_returns, mic_returns], axis=1).dropna()\nreturns.columns = ['Amazon', 'Microsoft']\n\nLet’s take a minute to check the data we are working with. The plot below shows 3 things: 1. The returns of one stock agains the returns of the other by period, with a regression line computed with the whole period. 2. The returns of both stocks. 3. The log prices of both stocks. I took the log for comparative purposes only.\nWe can clearly see that a regression line fitted on the whole data is not a good model for all periods. This is one of the main weaknesses of linear models like the Capital Asset Pricing Model (CAPM).\n\n#collapse-hide\n# linear model\nregression = LinearRegression()\nregression.fit(X=returns['Amazon'].values.reshape(-1,1), y=returns['Microsoft'])\ny_pred = regression.predict(returns['Amazon'].values.reshape(-1,1))\n\n# code taken from [1]\nplt.figure(figsize=(15,6))\ncm = plt.get_cmap('jet')\ncolors = np.linspace(0.1, 1, len(returns))\nsc = plt.scatter(returns['Amazon'], returns['Microsoft'], c=colors, cmap=cm, edgecolor='k', alpha=0.6)\nplt.plot(returns['Amazon'].values, y_pred, color='red', label='Regression Line')\ncb = plt.colorbar(sc)\n\ncb.ax.set_yticklabels([str(p.date()) for p in returns[::len(returns) // 9].index])\nplt.xlabel('AMAZON');\nplt.ylabel('MICROSOFT');\nplt.grid();\nplt.show()\n\n# ---------\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,4));\n\nreturns.plot(ax=ax[0])\nax[0].grid();\nax[0].set_title('Returns');\nax[0].legend()\n\nnp.log(prices).plot(ax=ax[1])\nax[1].grid();\nax[1].set_title('Log (Prices)');\nax[1].legend();\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow it is time to use the Kalman Filter. I’ve created my own Kalman library and that is what I am going to use. It is a multidimensional implementation, so we need to be careful when setting all the parameters.\nSince we want to estimate not only the beta but the alpha (intercept) too, we have to work in a 2-dimensional space; and that must hold for each time step.\nLet’s set the parameters 1 by 1, starting with the state transition model \\(A\\).\nThe state transition model \\(A\\) relates the state at the previous time step \\(k-1\\) to the state at the current step \\(k\\). Since stock returns can be considered random walks, \\(A\\) should be set to be the identity in order to model a martingale process. Notice how we create a 2x2 matrix for each time step.\n\nstock_a = returns['Amazon'].values\nstock_b = returns['Microsoft'].values\n\nn_steps = len(stock_a)\n\nA = np.array([np.eye(2)] * n_steps)\n\nNext, the control part. We are not going to use it, so we set them to None.\n\nB = None\nU = None\n\nWe continue the filter design by looking at the initial estimates. The Kalman must start somewhere and we are in charge of defining that place. We assume the initial mean estimates as zero, both for alpha and beta, and the initial covariance estimates as 1, also both for alpha and beta.\n\nxk = np.array([0, 0]) # initial mean\nPk = np.ones((2, 2)) # initial covariance\n\nTo continue, we define the observed variable \\(Z\\) and the observation model \\(H\\). The observed variable is the stock a (we could also choose the stock b).\nThe observation matrix relates the state to the measurement \\(z_{k}\\). Remember the equation \\(z_{k} = H_{k} x_{k} + r_{k}\\)? By setting the \\(H_{k}\\) to be stock b at time \\(k\\) we have a nice linear regression; we just have to add ones to account for the intercept.\n\nIt does not matter if we stack the ones before or after, we would just need to take care of selecting the right series after computing everything.\n\n\nZ = stock_a.copy()\nH = np.expand_dims(np.vstack([[stock_b], [np.ones(len(stock_b))]]).T, axis=1)\n\nLastly, we define the noises \\(Q\\) and \\(R\\). Given that we fixed the observation covariance to be one, the smaller is \\(Q\\) the slower the beta will change. Notice how we are making \\(Q\\) a diagonal matrix for each time step.\nThere is no need to put special shape in \\(R\\) since we want to add 1 in each time step for all elements and NumPy will take care of the broadcasting, but we may need to check the dimensions in other cases.\n\nQ = np.array([1e-3 * np.eye(2)] * n_steps) # process noise / transition covariance\nR = np.ones(n_steps) # measurement noise / observation covariance\n\nIt is time to run the filter. The library works by passing all the parameters except \\(Z\\) and \\(U\\) to the constructor and later use the filter method with \\(Z\\) and \\(U\\) to get the estimated means and covariances.\n\nkf = KalmanFilter(A=A, xk=xk, B=B, Pk=Pk, H=H, Q=Q, R=R)\nstates, errors = kf.filter(Z=Z, U=U)\n\n\n#collapse-hide\nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 6))\n\nax[0][0].plot(states[:, 0])\nax[0][0].set_title('Estimated means (beta)')\nax[0][0].grid()\n\nax[1][0].plot(states[:, 1])\nax[1][0].set_title('Estimated means (alpha / intercept)')\nax[1][0].grid()\n\nax[0][1].plot(errors[:, 0])\nax[0][1].set_title('Estimated covariances (beta)')\nax[0][1].grid()\n\nax[1][1].plot(errors[:, 1])\nax[1][1].set_title('Estimated covariances (alpha / intercept)')\nax[1][1].grid()\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n2.1. What’s next?\nNow you can use the estimated betas and alphas to perform a linear regression in an online fashion, updating the prior knowledge recursively with the observed variable.\n\n#collapse-hide\n# code taken from [1]\nplt.figure(figsize=(15,6))\ncm = plt.get_cmap('jet')\ncolors = np.linspace(0.1, 1, len(returns))\nsc = plt.scatter(returns['Amazon'], returns['Microsoft'], c=colors, cmap=cm, edgecolor='k', alpha=0.9)\nplt.plot(returns['Amazon'].values, y_pred, color='red', label='Regression Line')\ncb = plt.colorbar(sc)\n\n\nstep = 50\nspace = np.linspace(returns['Amazon'].min(), returns['Amazon'].max(), 2)\ncolors_l = np.linspace(0.1, 1, len(states[::step]))\nfor i, beta in enumerate(states[::step]):\n    plt.plot(space, beta[0] * space + beta[1], alpha=.2, lw=1, c=cm(colors_l[i]))\n\ncb.ax.set_yticklabels([str(p.date()) for p in returns[::len(returns) // 9].index])\nplt.xlabel('AMAZON');\nplt.ylabel('MICROSOFT');\nplt.grid();\nplt.show()\n\n\n\n\n\n\n\n\nThe dynamic beta and alpha provide a linear regression that adapts dynamically each time step. The regression line we created earlier is provided in red to compare. This looks much better!"
  },
  {
    "objectID": "posts/2021_08_15_online_beta_with_kalman_filter_checkpoint.html#conclusion",
    "href": "posts/2021_08_15_online_beta_with_kalman_filter_checkpoint.html#conclusion",
    "title": "Online beta estimation with the Kalman Filter",
    "section": "3. Conclusion",
    "text": "3. Conclusion\nIn this post we’ve seen how to perform online linear regression using the Kalman filter. The results are more realistic than a simple linear regression since they are computed updating prior distributions with new information.\nOne of the main drawbacks of the Kalman filter is that the assumptions of normality and linearity must hold in order for the filter to give us the optimal estimate [3].\nOverall, it is a very powerful and elegant technique that seems to outperform other models, like CAPM."
  },
  {
    "objectID": "posts/2021_08_15_online_beta_with_kalman_filter_checkpoint.html#references",
    "href": "posts/2021_08_15_online_beta_with_kalman_filter_checkpoint.html#references",
    "title": "Online beta estimation with the Kalman Filter",
    "section": "References",
    "text": "References\n\n[1] Quantopian - Kalman Filters\n[2] Quantdare - The Kalman Filter\n[3] Thrun, S., Burgard, W., & Fox, D. (2006). Probabilistic robotics. Kybernetes.\n[4] Kevin P. Murphy - Machine Learning: A probabilistic perspective.\n[5] Jerome H. Friedman, Robert Tibshirani & Trevor Hastie - The Elements of Statistical Learning."
  },
  {
    "objectID": "posts/08_08_2024_ml_notes_1.html",
    "href": "posts/08_08_2024_ml_notes_1.html",
    "title": "Machine Learning Notes I: Naive Bayes",
    "section": "",
    "text": "Personal notes for myself about Naive Bayes Classifier and how to implement it from scratch"
  },
  {
    "objectID": "posts/08_08_2024_ml_notes_1.html#introduction",
    "href": "posts/08_08_2024_ml_notes_1.html#introduction",
    "title": "Machine Learning Notes I: Naive Bayes",
    "section": "1. Introduction",
    "text": "1. Introduction\nNaive Bayes is a probabilistic model based on the Bayes’ Theorem. It can be used to perform classification tasks.\n\n1.1. Bayes’ Theorem\nThe Bayes theorem is a way of linking the conditional probabilities of two events \\(A\\) and \\(B\\). The conditional probability of \\(A\\) given \\(B\\) is defined as\n\\[\nP(A | B) = \\dfrac{\n    P(A \\cap B)\n}{\n    P(B)\n}.\n\\]\nSimilarly, the conditional probability of \\(B\\) given \\(A\\) is defined as\n\\[\nP(B | A) = \\dfrac{\n    P(B \\cap A)\n}{\n    P(A)\n} = \\dfrac{\n    P(A \\cap B)\n}{\n    P(A)\n}\n\\]\nWe can solve in the second equation for \\(P(A \\cap B)\\) and substitute in the first one to obtain the Bayes’ Theorem\n\\[\nP(A | B) = \\dfrac{\n    P(B | A) \\cdot P(A)\n}{\n    P(B)\n}\n\\]\n\n\n1.2. Classification using Bayes’ Theorem\nWe want to use the Bayes’ Theorem to classify a class \\(C\\) given a vector of features \\(X\\), so we formulate the problem as\n\\[\nP(C | X = (x_1, x_2, ..., x_n)) = \\dfrac{\n    P(X = (x_1, x_2, ..., x_n) | C) \\cdot P(C)\n}{\n    P(X)\n}\n\\]\nA vector of features \\(X = (x_1, x_2, ..., x_n)\\) whose class is unknown will be classified as the class that maximizes the probability \\(P(C | X = (x_1, x_2, ..., x_n))\\) such that\n\\[\nC = \\underset{C}{\\operatorname{argmax}} \\ P(C | X = (x_1, x_2, ..., x_n))\n\\]\n\n\n1.3. Optimizing the computations of terms and naive assumption\nNotice that the earlier expression is applied to each class, so we can avoid computing the marginal probability \\(P(X)\\)\n\\[\nP(C | X = (x_1, x_2, ..., x_n)) \\propto P(X = (x_1, x_2, ..., x_n) | C) \\cdot P(C),\n\\]\nwhich means we need to compute \\(P(C)\\) and \\(P(X = (x_1, x_2, ..., x_n))\\).\nTo compute \\(P(C)\\) we can simply get the frequency of the class \\(C\\) in the data using the ratio of favorable outcomes of \\(C\\) divided by the total number of outcomes. To compute the \\(P(C | X =(x_1, x_2, ..., x_n))\\) we would need to estimate the joint distribution, which would mean computing \\(2^n - 1\\) (-1 to remove the empty possibility) probabilities for each possible combination of \\(X=(x_1, x_2, ..., x_n)\\). One approach to simplify this computation is to assume the features are conditionally independent so the complexity becomes linear\n\\[\nP(X = (x_1, x_2, ..., x_n) | C) = P(x_1 | C) \\cdot P(x_2 | C) \\cdot ... \\cdot P(x_n | C) = \\prod_{i=1}^{n} P(x_i | C).\n\\]\nSo far, we have obtained the following expression to compute the posterior probabilities\n\\[\nP(C | X = (x_1, x_2, ..., x_n)) \\propto P(x_1 | C) \\cdot P(x_2 | C) \\cdot ... \\cdot P(x_n | C) \\cdot P(C) = P(C) \\cdot \\prod_{i=1}^{n} P(x_i | C).\n\\]\nSince probabilities are real numbers between 0 and 1 the product of probabilities may yield zeroed values. We can solve this issue by taking the logarithm to obtain the log-probabilities\n\\[\n\\log(P(C | X = (x_1, x_2, ..., x_n))) \\propto \\log(P(x_1 | C) \\cdot P(x_2 | C) \\cdot ... \\cdot P(x_n | C) \\cdot P(C)).\n\\]\nOne of the important properties of logarithms is \\(\\log(a \\cdot b) = \\log(a) + \\log(b)\\), so\n\\[\n\\log(P(C | X = (x_1, x_2, ..., x_n))) \\propto \\log(P(x_1 | C)) + \\log(P(x_2 | C)) + ... + \\log(P(x_n | C)) + \\log(P(C)) = \\log(P(C)) + \\sum_{i=1}^{n} \\log(P(x_i | C)).\n\\]\nA vector of features \\(X\\) will be assigned the class \\(C\\) that maximizes this log-prob:\n\\[\nC = \\underset{C}{\\operatorname{argmax}} \\ \\log(P(C)) + \\sum_{i=1}^{n} \\log(P(x_i | C)).\n\\]\nThe very last thing we need is defining \\(P(x_i | C)\\). Here, we can plug pretty much any probability distribution but for this example we are going to use the Gaussian distribution:\n\\[\nP(x_i | C) = \\dfrac{\n    1\n}{\n    \\sqrt{2 \\pi \\sigma_{C}^2}\n} \\cdot \\exp^{\n    -\\dfrac{\n        (x_{i} - \\mu_{C})\n    }{\n        2 \\sigma_{C}^2\n    }\n}\n\\]"
  },
  {
    "objectID": "posts/08_08_2024_ml_notes_1.html#coding-naive-bayes-from-scratch",
    "href": "posts/08_08_2024_ml_notes_1.html#coding-naive-bayes-from-scratch",
    "title": "Machine Learning Notes I: Naive Bayes",
    "section": "2. Coding Naive Bayes from scratch",
    "text": "2. Coding Naive Bayes from scratch\nWe first generate with the help of Scikit-Learn a synthetic dataset to perform the classification on.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.base import ClassifierMixin\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom scipy.stats import norm\n\n\nnp.random.seed(0)\n\n\nX, y = make_classification(n_samples=500, n_features=2, n_informative=2, n_redundant=0, n_classes=2, random_state=10)\n\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\nax.scatter(X[:, 0], X[:, 1], c=y)\nax.grid(True, alpha=.3)\nax.set_title(\"Dataset\", fontsize=24)\nax.set_xlabel(\"Feature $x_{1}$\", fontsize=20)\nax.set_ylabel(\"Feature $x_{2}$\", fontsize=20)\nax.tick_params(labelsize=20)\n\n\n\n\n\n\n\n\nWe are going to code the classifier following the Scikit-Learn API for fit-predict\n\nclass GaussianNaiveBayes(ClassifierMixin):\n    def __init__(self):\n        self.gaussian_params = {}\n        self.class_probabilities = {}\n\n    def fit(self, X, y):\n        class_probabilities = {}\n        gaussian_params = {}\n\n        class_labels = np.unique(y)\n        for c_label in class_labels:\n            mask = y == c_label\n            features = X[mask]\n\n            # compute the probability of C\n            c_freq = mask.sum() / len(mask)\n            class_probabilities[c_label] = c_freq\n\n            # compute the parameters of the Gaussian distribution\n            mean = features.mean(axis=0)\n            std = features.std(axis=0)\n\n            gaussian_params[c_label] = {}\n            gaussian_params[c_label][\"mean\"] = mean\n            gaussian_params[c_label][\"std\"] = std\n\n        self.gaussian_params = gaussian_params\n        self.class_probabilities = class_probabilities\n\n    def predict(self, X):\n        gaussian_params = self.gaussian_params\n        class_probabilities = self.class_probabilities\n\n        class_labels = np.array(list(class_probabilities.keys()))\n        predictions = np.empty(shape=(X.shape[0], len(class_labels)))\n\n        for i, c_label in enumerate(class_labels):\n            mean = gaussian_params[c_label][\"mean\"]\n            std = gaussian_params[c_label][\"std\"]\n            p_xi_given_C = np.log(norm.pdf(X, loc=mean, scale=std)).sum(axis=1)\n            predictions[:, i] = p_xi_given_C + np.log(class_probabilities[c_label])\n        \n        return np.argmax(predictions, axis=1)\n\nWe test our model using a K-fold validation approach of 5 splits. We are going to compute the ROC AUC score to measure the classification goodness (we assume TPR and FPR are equally important and thus, this metric is appropriate).\n\nkf = KFold(n_splits=5)\n\n\nroc_scores = []\nfor train_idx, test_idx in kf.split(X):\n    model = GaussianNaiveBayes()\n\n    X_train = X[train_idx]\n    y_train = y[train_idx]\n\n    X_test = X[test_idx]\n    y_test = y[test_idx]\n\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    score = roc_auc_score(y_true=y_test, y_score=y_pred)\n    roc_scores.append(score)\n\nOur naive model performs really well for this dataset, with a mean of .92 area under the curve.\n\nnp.array(roc_scores).mean()\n\n0.927491169202372"
  },
  {
    "objectID": "posts/08_08_2024_ml_notes_1.html#strengths-and-weaknesses",
    "href": "posts/08_08_2024_ml_notes_1.html#strengths-and-weaknesses",
    "title": "Machine Learning Notes I: Naive Bayes",
    "section": "3. Strengths and Weaknesses",
    "text": "3. Strengths and Weaknesses\nA summary of strenghts and weaknesses of this model.\n\nPros\n\nVery easy to implement and train.\nComputational complexity of \\(O(n)\\), with \\(n\\) being the number of samples.\nGood class estimator.\nWorks well with small datasets.\nSeems to perfrom well on text classification.\n\n\n\nCons\n\nAssumes conditionally independent features, which may lead to poor performance in a dataset with correlated features.\nNot very good probability estimator.\nLimited at capturing complex relationships between the features."
  },
  {
    "objectID": "posts/09_08_2024_ml_notes_2.html",
    "href": "posts/09_08_2024_ml_notes_2.html",
    "title": "Machine Learning Notes II: KNN",
    "section": "",
    "text": "Personal notes for myself about K-nearest neighbor and how to implement it from scratch.\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial.distance import euclidean\nfrom functools import partial\n\nfrom sklearn.datasets import make_classification, make_regression\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score, r2_score\nfrom scipy.stats import mode"
  },
  {
    "objectID": "posts/09_08_2024_ml_notes_2.html#introduction",
    "href": "posts/09_08_2024_ml_notes_2.html#introduction",
    "title": "Machine Learning Notes II: KNN",
    "section": "1. Introduction",
    "text": "1. Introduction\nK-Nearest Neighbouts is a supervised learning algorithm that works based on distance metrics. A new point is classified as the \\(k\\) closest neighbours in the space to this new point.\n\n1.1. Algorithm\nKnn algorithm is probably one of the simplest machine learning models yet it still yields effective results. The idea is to represent the labelled points in the space and classify or regress a new unlabelled point by looking at the labels of the \\(K\\) closests neighbours.\nLet’s visualize an example. Below, we observe a dataset composed of 10 points. Each point has a label associated. We want to classificy the point in red. Which label do we assign to it?\n\ndef plot_knn(k_val=None):\n    np.random.seed(3)\n    X = np.random.normal(0, 0.05, size=(10, 2))\n    y = np.random.choice([0, 1], size=len(X))\n    new_point = np.random.normal(0, 0.05, size=2)\n\n    # Compute Euclidean distance from new_point to the rest of the points\n    euclidean_from_new_point = partial(euclidean, v=new_point)\n    distances = np.apply_along_axis(euclidean_from_new_point, axis=1, arr=X)\n    dist_idx_sort = np.argsort(distances)\n\n    # Plot\n    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=300)\n    ax.scatter(new_point[0], new_point[1], c=\"red\", marker=\"*\", s=300)\n\n    if k_val is not None:\n        # Sort X based on distance and select the closest k_val points\n        closest_points = X[dist_idx_sort][:k_val]\n        closest_distances = distances[dist_idx_sort][:k_val]\n        \n        # Plot arrows to the closest k_val points\n        for i in range(closest_points.shape[0]):\n            x_target, y_target = closest_points[i]\n            distance = closest_distances[i]\n            \n            # Draw arrow from new_point to the closest point\n            ax.annotate(\n                '',\n                xy=(x_target, y_target),\n                xytext=(new_point[0], new_point[1]),\n                arrowprops=dict(\n                    facecolor='blue',\n                    edgecolor='blue',\n                    arrowstyle='-&gt;',\n                    lw=2,\n                ),\n            )\n            \n            # Calculate the midpoint for placing the text\n            mid_point = (new_point + closest_points[i]) / 2\n            ax.text(\n                mid_point[0], \n                mid_point[1], \n                f'{distance:.2f}', \n                color='blue',\n                fontsize=12,\n                ha='center',\n                va='center'\n            )\n\n    ax.grid(True, alpha=.3)\n\n    if k_val is None:\n        ax.set_title(\"Dataset\", fontsize=24)\n    else:\n        ax.set_title(f\"Dataset | k: {k_val}\", fontsize=24)\n    ax.set_xlabel(\"Feature $x_{1}$\", fontsize=20)\n    ax.set_ylabel(\"Feature $x_{2}$\", fontsize=20)\n    ax.tick_params(labelsize=20)\n\n\nplot_knn()\n\n\n\n\n\n\n\n\nKnn uses a distance metric, like Euclidean distance, to determine the closest neighbours and takes the mode value of its labels to decide which class to assign to the new point. If we were working with continuous values we would assign the average or median value of the labelled datapoints to the new point.\nBelow I show the plots for the K-nearest neightbours for different values of \\(K\\).\n\nplot_knn(k_val=3)\nplot_knn(k_val=7)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice that the same point could be assigned to different classes depending on the \\(K\\) value. In addition, it is better to select an odd value for \\(K\\) to avoid ties."
  },
  {
    "objectID": "posts/09_08_2024_ml_notes_2.html#coding-a-knn-from-scratch",
    "href": "posts/09_08_2024_ml_notes_2.html#coding-a-knn-from-scratch",
    "title": "Machine Learning Notes II: KNN",
    "section": "2. Coding a Knn from scratch",
    "text": "2. Coding a Knn from scratch\nWe code the Knn following Scikit-Learn API for machine learning algorithms. The distance metric can be passed as a callable\n\nclass KNNModel:\n    def __init__(self, is_classification, k_neighbours=3, distance=euclidean):\n        self.is_classification = is_classification\n        self.k_neighbours = k_neighbours\n        self.distance = distance\n\n        # attributes\n        self.X_train = None\n        self.y_train = None\n\n    def fit(self, X, y):\n        self.X_train = X\n        self.y_train = y\n\n    def predict(self, X):\n        k_neighbours = self.k_neighbours\n        is_classification = self.is_classification\n        distance = self.distance\n        y_train = self.y_train\n        X_train = self.X_train\n\n        n_samples = X.shape[0]\n        predictions = np.empty(shape=(n_samples, 1))\n        for i, x_sample in enumerate(X):\n            distance_from_new_point = partial(distance, v=x_sample)\n            distances = np.apply_along_axis(\n                distance_from_new_point, axis=1, arr=X_train\n            )\n            dist_idx_sort = np.argsort(distances)\n\n            k_closest_labels = y_train[dist_idx_sort][:k_neighbours]\n            if is_classification:\n                predictions[i] = mode(k_closest_labels).mode\n            else:\n                predictions[i] = np.mean(k_closest_labels)\n\n        return predictions\n\n\n2.1. Classification\nWe test our model using a classification dataset.\n\nX, y = make_classification(n_samples=500, n_features=2, n_informative=2, n_redundant=0, n_classes=2, random_state=10)\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\nax.scatter(X[:, 0], X[:, 1], c=y)\nax.grid(True, alpha=.3)\nax.set_title(\"Dataset\", fontsize=24)\nax.set_xlabel(\"Feature $x_{1}$\", fontsize=20)\nax.set_ylabel(\"Feature $x_{2}$\", fontsize=20)\nax.tick_params(labelsize=20)\n\n\n\n\n\n\n\n\n\nkf = KFold(n_splits=5)\n\nroc_scores = []\nfor train_idx, test_idx in kf.split(X):\n    model = KNNModel(is_classification=True, distance=euclidean)\n\n    X_train = X[train_idx]\n    y_train = y[train_idx]\n\n    X_test = X[test_idx]\n    y_test = y[test_idx]\n\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    score = roc_auc_score(y_true=y_test, y_score=y_pred)\n    roc_scores.append(score)\n\nWe find this naive implementation works pretty well for the generated dataset, with an average of 0.95 ROC AUC score within 5 k-fold framework.\n\nnp.array(roc_scores).mean()\n\n0.9520628722985057\n\n\n\n\n2.2. Regression\nWhat about regression. We perform the same process but using a regression dataset and algorithm\n\nX, y = make_regression(n_samples=500, n_features=1, n_informative=1, n_targets=1, noise=10, random_state=0)\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\nax.scatter(X, y)\nax.grid(True, alpha=.3)\nax.set_title(\"Dataset\", fontsize=24)\nax.set_xlabel(\"Feature $x_{1}$\", fontsize=20)\nax.set_ylabel(\"Label\", fontsize=20)\nax.tick_params(labelsize=20)\n\n\n\n\n\n\n\n\n\nkf = KFold(n_splits=5)\n\nr2_scores = []\nfor train_idx, test_idx in kf.split(X):\n    model = KNNModel(is_classification=False, distance=euclidean)\n\n    X_train = X[train_idx]\n    y_train = y[train_idx]\n\n    X_test = X[test_idx]\n    y_test = y[test_idx]\n\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    score = r2_score(y_true=y_test, y_pred=y_pred)\n    r2_scores.append(score)\n\nAgain, this naive model yields pretty good results on the synthetic regression dataset, with an average r2 score of 0.93\n\nnp.array(r2_scores).mean()\n\n0.9344901211500038"
  },
  {
    "objectID": "posts/09_08_2024_ml_notes_2.html#strengths-and-weaknesses",
    "href": "posts/09_08_2024_ml_notes_2.html#strengths-and-weaknesses",
    "title": "Machine Learning Notes II: KNN",
    "section": "3. Strengths and Weaknesses",
    "text": "3. Strengths and Weaknesses\nA summary of strenghts and weaknesses of this model.\n\nPros\n\nSimple to understand and implement.\nNo assumptions about data distribution.\nEffective in small, well-separated datasets.\nAdapts easily to new data (lazy learner).\n\n\n\nCons\n\nComputationally expensive during prediction, especially with large datasets. \\(O(n \\cdot d \\cdot k)\\), where \\(n\\) is the number of samples, \\(d\\) is the number of dimensions, and \\(k\\) is the number of neighbors.\nSensitive to irrelevant features and noise.\nRequires feature scaling for optimal performance.\nStruggles with high-dimensional data (curse of dimensionality)."
  },
  {
    "objectID": "posts/17_08_2024_ml_notes_3.html",
    "href": "posts/17_08_2024_ml_notes_3.html",
    "title": "Machine Learning Notes III: Linear Regression",
    "section": "",
    "text": "Personal notes for myself about linear regression and how to implement it from scratch using least squares and gradient descent.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import r2_score\nfrom sklearn.base import RegressorMixin"
  },
  {
    "objectID": "posts/17_08_2024_ml_notes_3.html#introduction",
    "href": "posts/17_08_2024_ml_notes_3.html#introduction",
    "title": "Machine Learning Notes III: Linear Regression",
    "section": "1. Introduction",
    "text": "1. Introduction\nLinear regression models the relationship between a dependent variable and one or more independent variables using a linear approach. The dependent variable is constructed as a linear combination of the indepent variables plus some noise. In matrix form, linear regression is expressed as\n\\[\nY = X \\cdot B + \\epsilon,\n\\]\nwhere \\(Y\\) is a vector of size \\((n, 1)\\), \\(X\\) is a matrix of size \\((n, p+1)\\) representing the independent variables, \\(B\\) is a vector of size \\((p+1, 1)\\) representing the coefficients that weight the features, \\(\\epsilon\\) is a vector of size \\((n, 1)\\) and \\(n\\) and \\(p\\) are the number of samples and features respectively.\n\n1.1. Least squares solution\nHow do we optimize the coefficients? We can find the vector of \\(B\\) that minimizes the residuals between the prediction and the true value. We have a function \\(S\\) to minimize that depends on the parameters \\(B\\)\n\\[\nS(B) = \\sum_j \\epsilon_{j}^2 = (Y - X \\cdot B)^{T} \\cdot (Y - X \\cdot B).\n\\]\nSince \\(S(B)\\) is a quadratic function its minimum exists albeit is not unique. Let’s expand the above expression\n\\[\nS(B) = Y^T Y - Y^T X B - B^T X^T Y + B^T X^T X B.\n\\]\nWe now differentiate \\(S\\) with respect to \\(B\\)\n\\[\n\\dfrac{\n    d S(B)\n}{\n    dB\n} = 0 -2 X^T Y + 2 X^T X B.\n\\]\nTo find the minum, we do \\(\\dfrac{d S(B)}{B}=0\\)\n\\[\n-2 X^T Y + 2 X^T X B = 0 \\rightarrow X^T X B = X^T Y,\n\\]\nand then we solve for \\(B\\)\n\\[\nB = (X^T X)^{-1} X^T Y.\n\\]\n\n\n1.1. Gradient descent\nAnother way of finding the parameters for the linear regression model is to ask the following question “how does the error change when the parameters changes?”. The answer to this question provides a path that we can follow iteratively to reach the minimum error.\nWe quantify the change in the error with respect to the parameters we use the derivative. Let’s say we want to use the mean squared error (MSE) as a loss function \\(L\\) to measure how accurate the estimated predictions \\(\\hat{Y}\\) are with respect to the real values \\(Y\\):\n\\[\nL(B) = \\dfrac{1}{N} || Y - \\hat{Y}||^{2} = \\dfrac{1}{N}  \\left( Y -  \\hat{Y} \\right)^{T}\\left( Y -  \\hat{Y} \\right).\n\\]\nHere, the MSE is the norm 2 of the differences between the estimated values and the real values.\nWe now take the derivative of the loss function with respect to \\(B\\). Refer to the previous section for a more complete proof.\n\\[\n\\dfrac{\n    d S(B)\n}{\n    dB\n} = \\dfrac{1}{N} \\left( 0 -2 X^T Y + 2 X^T X B \\right) = \\dfrac{-2}{N} X^T \\left( Y - XB \\right).\n\\]\nHaving computed how much the error changes depending on the variation of the parameters \\(B\\) we now use this information to update \\(B\\) such that\n\\[\nB = B - \\eta \\dfrac{d L(B)}{d B},\n\\]\nwhere \\(\\eta\\) is the learning rate, a parameter used to control how small or big the new changes are.\nThe above operation is repeated for a fixed number of times called epochs. Each epoch represents a full traverse of the data \\(X\\). We can traverse the data in 3 ways:\n\nBatch: we use all elements of \\(X\\) at once.\nMini-batch:: we use a subset \\(V\\) of elements of \\(X\\) such that \\((1 &lt; n_V &lt; n_X)\\), where \\(n\\) represents the number of rows\nStochastic:: we use a subset \\(V\\) of elements of \\(X\\) such that \\((n_V = 1)\\)"
  },
  {
    "objectID": "posts/17_08_2024_ml_notes_3.html#coding-linear-regression-from-scratch",
    "href": "posts/17_08_2024_ml_notes_3.html#coding-linear-regression-from-scratch",
    "title": "Machine Learning Notes III: Linear Regression",
    "section": "2. Coding linear regression from scratch",
    "text": "2. Coding linear regression from scratch\nBelow we find the code for both approaches: the ordinary least squares and the gradient descent method. The code is a direct translation of the math explained above.\n\nclass OLSLinearRegression(RegressorMixin):\n    \"\"\"Ordinary least squares regression.\n\n    Parameters\n    ----------\n    fit_intercept : bool, optional, default: True\n        True to fit the intercept of the linear regression.\n    \"\"\"\n    def __init__(self, fit_intercept=True):\n        self.fit_intercept = fit_intercept\n        self.coefficients_ = None\n\n    def fit(self, X, y):\n        if X.ndim != 2:\n            raise ValueError(\"Number of dims in features matrix must be 2\")\n\n        fit_intercept = self.fit_intercept\n        if fit_intercept:\n            n_features = len(X)\n            ones_col = np.ones((n_features, 1))\n            X = np.hstack((ones_col, X))\n\n        coeff = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y)) \n        #coeff = np.linalg.inv(X.T @ X) @ X.T @ y\n        self.coefficients_ = coeff\n\n    def predict(self, X):\n        fit_intercept = self.fit_intercept\n        coeff = self.coefficients_\n        \n        if fit_intercept:\n            return X @ coeff[1:] + coeff[0]\n        else:\n            return X @ coeff\n\nThe gradient descen optimization uses the mean squared error but it can be changed by deriving the appropiate formulas and changing them in the code.\n\nclass GDLinearRegression(RegressorMixin):\n    \"\"\"Gradient descent linear regression.\n\n    Estimates the parameters using a gradient descent optimization\n    approach.\n    \n    Parameters\n    ----------\n    l_rate : float, optional, default: 1e-3\n        Learning rate.\n    batch_size : int, optional, default: 1\n        Batch size for the gradient descent algorithm. 1 will perform\n        a stochastic gradient descent.\n    \"\"\"\n    def __init__(\n        self,\n        l_rate=1e-3,\n        batch_size=1,\n        fit_intercept=True,\n        n_epochs=1_000\n    ):\n        self.l_rate = l_rate\n        self.batch_size = batch_size\n        self.fit_intercept = fit_intercept\n        self.n_epochs = n_epochs\n\n        # attributes\n        self.coefficients_ = None\n        self.loss = []\n\n    def _mse_loss(self, y_true, y_est):\n        return ((y_true - y_est) ** 2).mean()\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        n_epochs = self.n_epochs\n        fit_intercept = self.fit_intercept\n        l_rate = self.l_rate\n        batch_size = self.batch_size\n        \n        if fit_intercept:\n            X = np.hstack((np.ones((n_samples, 1)), X))\n\n        coefficients_ = np.zeros(X.shape[1])\n\n        for _ in range(n_epochs):\n            for i in range(0, n_samples, batch_size):\n                X_batch = X[i:i + batch_size]\n                y_batch = y[i:i + batch_size]\n\n                # make prediction\n                prediction = X_batch @ coefficients_\n\n                # compute loss\n                _loss = self._mse_loss(y_batch, prediction)\n                self.loss.append(_loss)\n\n                # compute gradient\n                gradient = -(2 / batch_size) * X_batch.T @ (y_batch - prediction)\n\n                # update parameters\n                coefficients_ -= l_rate * gradient\n\n        self.coefficients_ = coefficients_\n\n    def predict(self, X):\n        if self.fit_intercept:\n            X = np.hstack((np.ones((X.shape[0], 1)), X))\n\n        return X @ self.coefficients_\n\n\n2.1. OLS example\nWe use the ordinary least squares solution on the following dataset\n\nX, y = make_regression(n_samples=500, n_features=1, n_informative=1, n_targets=1, noise=10, random_state=0)\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\nax.scatter(X, y)\nax.grid(True, alpha=.3)\nax.set_title(\"Dataset\", fontsize=24)\nax.set_xlabel(\"Feature $x_{1}$\", fontsize=20)\nax.set_ylabel(\"Label\", fontsize=20)\nax.tick_params(labelsize=20)\n\n\n\n\n\n\n\n\n\nkf = KFold(n_splits=5)\n\nr2_scores = []\nfor train_idx, test_idx in kf.split(X):\n    model = OLSLinearRegression()\n\n    X_train = X[train_idx]\n    y_train = y[train_idx]\n\n    X_test = X[test_idx]\n    y_test = y[test_idx]\n\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    score = r2_score(y_true=y_test, y_pred=y_pred)\n    r2_scores.append(score)\n\nPretty good results from this naive model on the synthetic dataset\n\nnp.array(r2_scores).mean()\n\n0.9534244993205533\n\n\n\n\n2.2. Gradient descent example\nWe perform the very same thing using the gradient descent solution\n\nkf = KFold(n_splits=5)\n\nr2_scores = []\nfor train_idx, test_idx in kf.split(X):\n    model = GDLinearRegression(batch_size=32, n_epochs=10_000)\n\n    X_train = X[train_idx]\n    y_train = y[train_idx]\n\n    X_test = X[test_idx]\n    y_test = y[test_idx]\n\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    score = r2_score(y_true=y_test, y_pred=y_pred)\n    r2_scores.append(score)\n\nIt takes a bit longer due to the iterative nature of the algorithm but we achieve the same results.\n\nnp.array(r2_scores).mean()\n\n0.9534223387121132\n\n\nIf we take the last model and plot its loss we observe a clear decrease the more batches we perform:\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\nax.plot(model.loss)\nax.grid(True, alpha=.3)\n\nax.set_title(\"MSE Loss evolution\", fontsize=24)\nax.set_xlabel(\"Batch \", fontsize=20)\nax.set_ylabel(\"Loss\", fontsize=20)\nax.tick_params(labelsize=20)"
  },
  {
    "objectID": "posts/17_08_2024_ml_notes_3.html#strengths-and-weaknesses",
    "href": "posts/17_08_2024_ml_notes_3.html#strengths-and-weaknesses",
    "title": "Machine Learning Notes III: Linear Regression",
    "section": "3. Strengths and Weaknesses",
    "text": "3. Strengths and Weaknesses\nA summary of strenghts and weaknesses of this model.\n\nPros\n\nSimple and escalable.\nInterpretable.\nEfficient for large datasets with linear relationships.\n\n\n\nCons\n\nAssumes linear relationships.\nSensitive to outliers.\nLimited at handling complex relationships"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "xy = lambda",
    "section": "",
    "text": "Machine Learning Notes IV: Logistic Regression\n\n\n\n\n\n\nmachine learning\n\n\npython\n\n\nlogistic regression\n\n\n\n\n\n\n\n\n\nAug 20, 2024\n\n\nAlejandro Pérez Sanjuán\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning Notes III: Linear Regression\n\n\n\n\n\n\nmachine learning\n\n\npython\n\n\nlinear regression\n\n\n\n\n\n\n\n\n\nAug 17, 2024\n\n\nAlejandro Pérez Sanjuán\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning Notes II: KNN\n\n\n\n\n\n\nmachine learning\n\n\npython\n\n\nknn\n\n\n\n\n\n\n\n\n\nAug 9, 2024\n\n\nAlejandro Pérez Sanjuán\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning Notes I: Naive Bayes\n\n\n\n\n\n\nmachine learning\n\n\npython\n\n\nnaive bayes\n\n\n\n\n\n\n\n\n\nAug 8, 2024\n\n\nAlejandro Pérez Sanjuán\n\n\n\n\n\n\n\n\n\n\n\n\nIndex Tracking: a naive approach\n\n\n\n\n\n\nfinance\n\n\nanalysis\n\n\npython\n\n\nindex tracking\n\n\n\n\n\n\n\n\n\nJul 28, 2024\n\n\nAlejandro Pérez Sanjuán\n\n\n\n\n\n\n\n\n\n\n\n\nOnline beta estimation with the Kalman Filter\n\n\n\n\n\n\nfinance\n\n\npython\n\n\ntracking\n\n\nbayes\n\n\nfiltering\n\n\n\n\n\n\n\n\n\nAug 15, 2021\n\n\nAlejandro Pérez Sanjuán\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Python to construct dollar indices\n\n\n\n\n\n\nfinance\n\n\npython\n\n\n\n\n\n\n\n\n\nJul 9, 2021\n\n\nAlejandro Pérez Sanjuán\n\n\n\n\n\n\nNo matching items"
  }
]